.. _introduction:

=======
Увод
=======

Последњих деценија преферирају се различите методе дубоког учења решавање разних врста проблема, као што су препознавање слике, препознавање говора, обрада природног језика (*Natural Language Processing* - NLP), претраживање, системи за препоруке, биоинформатика итд. Међутим, традиционално надгледано дубоко учење није погодно за решавање баш свих врста проблема, без обзира на довољну количину доступних података који описују понашање моделованог система. Конкретно, проблеми описани кроз линеарне и нелинеарне једначине и системи једначина нису били у фокусу дубоког учења. Класичне нумеричке методе и даље држе апсолутни примат у нумеричком решавању парцијалних диференцијалних једначина. Методе као што су коначне разлике (*Finite Difference Method*), коначне запремине (*Finite Volume Method*), и коначни елементи (*Finite Element Method*) се и даље сматрају најсавременијим методама због њихове ефикасности и могућности примене у широком спектру области.

Међутим, решавање инверзних проблема класичним нумеричким методама захтева прорачуне који су изузетно рачунарски и временски захтевни, јер претрага за непознатим параметрима модела укључује итеративни поступак. Због тога се тачност често жртвује за ефикасност. Ове врсте претрага често нису исцрпне и укључују тзв. мета-хеуристике, без гаранције да ће се пронаћи најбоље (оптимално) решење. Примери из праксе аутора најчешће користе генетске алгоритме (*Genetic Algorithm* - GA), спроводе оптимизацију базирану на симулацији (*Simulation Based Optimization*) и захтевају употребу више стотина процесора да би се до решења које није гарантовано оптимално дошло у иоле разумном временском року. (**наше референце**)

Да би се елиминисали ови недостаци нумеричких метода, развијена је нова метода дубоког учења за решавање парцијалних диференцијалних једначина. Та методa, под именом **Неуронске мреже засноване на физици** (*Physics Informed Neural Netorks* - PINN), користи се за решавање проблема надгледаног учења уз поштовање било ког закона физике описане општим нелинеарним парцијалним диференцијалним једначинама **\ците{Раисси2017}**.

Главна иновација PINN-ова у поређењу са класичним неуронским мрежама је увођење функције губитка која кодира основне једначине физике, узима излаз дубоке мреже, која се зове апроксиматор, и израчунава а вредност губитка **\ците{СМакидис}**. Функција губитка која се односи на  диференцијалну једначину се минимизира обуком апроксиматорске неуронске мреже, где се диференцијални оператори примењују коришћењем аутоматске диференцијације.

Неурална мрежа заснована на физици је техника машинског учења која може се користити за апроксимацију решења парцијалне диференцијалне једначине. Парцијалне диференцијалне једначине са одговарајућим почетним и граничним условима могу се изразити у општем облику као:


.. math::
    :name: eq:osnovne

    u_{t}\mathcal{+ N}\lbrack u\rbrack &= 0,\ \ X \in \Omega,\ t \in \lbrack 0,T\rbrack, \\
    u(X,0) &= h(X),\ \ X \in \Omega, \\
    u(X,t) &= g(X,t),\ \ X \in \Omega_{g},\ t \in \lbrack 0,T\rbrack.
